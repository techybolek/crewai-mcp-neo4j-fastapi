# LangFuse Configuration for LLM Tracing
# Get these from https://cloud.langfuse.com or your self-hosted instance

# Required for LangFuse tracing
LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key-here
LANGFUSE_SECRET_KEY=sk-lf-your-secret-key-here

# Optional - defaults to https://cloud.langfuse.com
LANGFUSE_HOST=https://cloud.langfuse.com

# Optional - FastAPI server port
PORT=4000

# OpenAI API Key (if using OpenAI instead of Ollama)
# OPENAI_API_KEY=your-openai-key-here